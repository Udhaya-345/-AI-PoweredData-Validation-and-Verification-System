{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0bbf842-39aa-4a19-a1c1-a041738a8bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "GROQ_API_KEY = \"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\"\n",
    "\n",
    "def chat_with_llm_model1(user_message, history=None, temperature=0.7):\n",
    "    \n",
    "    API_URL = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "    MODEL = \"llama3-70b-8192\"\n",
    "\n",
    "    HEADERS = {\"Authorization\": f\"Bearer {GROQ_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"}\n",
    "\n",
    "\n",
    "    if history is None:\n",
    "        history = []\n",
    "\n",
    "    history.append({\"role\": \"user\", \"content\": user_message})\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": history,\n",
    "        \"temperature\": temperature\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(API_URL, headers=HEADERS, json=payload)\n",
    "        response.raise_for_status()\n",
    "        reply = response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "        print(reply)\n",
    "        return reply\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"Request failed: {str(e)}\"\n",
    "\n",
    "OPENROUTER_API_KEY = \"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\"  # For API - https://openrouter.ai\n",
    "\n",
    "def chat_with_llm_model2(user_message, history=None, temperature=0.7):\n",
    "    API_URL = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "    MODEL = \"mistralai/mixtral-8x7b-instruct\"  \n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"HTTP-Referer\": \"https://yourdomain.com\", \n",
    "        \"X-Title\": \"Your App or Project Name\"\n",
    "    }\n",
    "\n",
    "    if history is None:\n",
    "        history = []\n",
    "\n",
    "    history.append({\"role\": \"user\", \"content\":user_message})\n",
    "\n",
    "    payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": history,\n",
    "        \"temperature\": temperature,\n",
    "        \"stream\": False\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(API_URL, headers=headers, json=payload)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        reply = response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "        reply = reply.strip()\n",
    "        print(reply)\n",
    "        return reply\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"Request failed: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f97dd929-45e3-44da-a959-de7ace50c2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Excel file.\n",
      "Loading prompt from text file.\n"
     ]
    }
   ],
   "source": [
    "# Load the Excel file and the specific sheet\n",
    "file_path = r\"C:\\Users\\Udhaya\\Desktop\\Udhaya DA Files\\Power BI (Sir File)\\City_Name\\city_name.xlsx\"\n",
    "sheet_name = 'Cosmo Input Report'\n",
    "print(\"Loading Excel file.\")\n",
    "df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "\n",
    "# Load the prompt from the text file\n",
    "print(\"Loading prompt from text file.\")\n",
    "with open(r\"C:\\Users\\Udhaya\\Desktop\\Udhaya DA Files\\Power BI (Sir File)\\City_Name\\prompt.txt\") as file:\n",
    "    prompt_template = file.read()\n",
    "\n",
    "# Check for result columns and add them if they don't exist\n",
    "for col in ['Result_Model1', 'Result_Model2', 'City_Check']:\n",
    "    if col not in df.columns:\n",
    "        df[col] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f06fd870-90aa-4527-ab57-4240c3eb7e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting parallel processing of rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   0%|                                                                          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a. City name available and main city matching\n",
      "a. City name available and main city matching\n",
      "a. City name available and main city matching\n",
      "a. City name available and main city matching\n",
      "a. City name available and main city matching\n",
      "a. City name available and main city matching\n",
      "a. City name available and main city matching\n",
      "A. City name available and main city matching\n",
      "a. City name available and main city matching\n",
      "a. City name available and main city matching\n",
      "a. City name available and main city matching\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   7%|████▍                                                             | 1/15 [00:06<01:32,  6.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a. City name available and main city matching\n",
      "A. City name available and main city matching\n",
      "a. City name available and main city matching\n",
      "a. City name available and main city matching\n",
      "a. City name available and main city matching\n",
      "a. City name available and main city matching\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  27%|█████████████████▌                                                | 4/15 [00:09<00:21,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a. City name available and main city matching\n",
      "a. City name available and main city matching\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  47%|██████████████████████████████▊                                   | 7/15 [00:10<00:08,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a. City name available and main city matching\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  53%|███████████████████████████████████▏                              | 8/15 [00:10<00:05,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a. City name available and main city matching\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  60%|███████████████████████████████████████▌                          | 9/15 [00:11<00:04,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a. City name available and main city matching\n",
      "a. City name available and main city matching\n",
      "a. City name available and main city matching\n",
      "a. City name available and main city matching\n",
      "a. City name available and main city matching\n",
      "a. City name available and main city matching\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  67%|███████████████████████████████████████████▎                     | 10/15 [00:13<00:06,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a. City name available and main city matching\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  73%|███████████████████████████████████████████████▋                 | 11/15 [00:14<00:04,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a. City name available and main city matching\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  87%|████████████████████████████████████████████████████████▎        | 13/15 [00:15<00:01,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a. City name available and main city matching\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows: 100%|█████████████████████████████████████████████████████████████████| 15/15 [00:18<00:00,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished processing all rows\n",
      "Verifying model results and updating 'Result_Check' column.\n",
      "Total rows processed: 15\n",
      "Correct matches: 13\n",
      "Rows where Result_Model1 is wrong: 0\n",
      "Rows where Result_Model2 is wrong: 2\n",
      "Rows where model comparison was not needed: 0\n",
      "Saving the results to Excel.\n",
      "Processing completed and file saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "MAX_THREADS = 5\n",
    "matches = 0\n",
    "# Function to process each row and update results for both models\n",
    "def process_row(index, row):\n",
    "    main_city = row['Source City name']\n",
    "    description = row['Description']\n",
    "    prompt = prompt_template.format(main_city=main_city, description=description)\n",
    "\n",
    "    result_model1 = chat_with_llm_model1(prompt)\n",
    "    result_model2 = chat_with_llm_model2(prompt)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    city_name_lower = main_city.lower()\n",
    "    description_lower = description.lower()\n",
    "    city_check = (city_name_lower in description_lower) or (f\"{city_name_lower}'s\" in description_lower)\n",
    "    \n",
    "    city_check_result = \"City name available and matching\" if city_check else \"City name not available or mismatched\"\n",
    "    \n",
    "    return index, result_model1, result_model2, city_check_result\n",
    "\n",
    "# Parallel processing of the rows\n",
    "total_rows = len(df)\n",
    "print(\"Starting parallel processing of rows.\")\n",
    "with ThreadPoolExecutor(max_workers=MAX_THREADS) as executor:\n",
    "    futures = {executor.submit(process_row, i, row): i for i, row in df.iterrows()}\n",
    "    for future in tqdm(futures, total=total_rows, desc=\"Processing Rows\"):\n",
    "        i, result_model1, result_model2, city_check_result = future.result()\n",
    "        df.at[i, 'Result_Model1'] = result_model1\n",
    "        df.at[i, 'Result_Model2'] = result_model2\n",
    "        df.at[i, 'City_Check'] = city_check_result\n",
    "    print(\"finished processing all rows\")\n",
    "\n",
    "def verify_model_results(row):\n",
    "    expected_result = \"a. City name available and main city matching\"\n",
    "    city_check_phrase = \"City name available and matching\"\n",
    "    model1_status = \"Correct\" if row['Result_Model1'] == expected_result else \"Result_Model1 is wrong\"\n",
    "    model2_status = \"Correct\" if row['Result_Model2'] == expected_result else \"Result_Model2 is wrong\"\n",
    "    overall_status = \"\"\n",
    "\n",
    "    if row['City_Check'] == city_check_phrase:\n",
    "        if row['Result_Model1'] != expected_result:\n",
    "            overall_status += model1_status\n",
    "        if row['Result_Model2'] != expected_result:\n",
    "            overall_status += \" and \" + model2_status if overall_status else model2_status\n",
    "    else:\n",
    "        # If City_Check is not as expected, no comparison is required with model results.\n",
    "        overall_status = \"City not matching, no need to check models.\"\n",
    "    \n",
    "    return overall_status if overall_status else \"Correct\"\n",
    "\n",
    "# Ensure the fourth column exists\n",
    "if 'Result_Check' not in df.columns:\n",
    "    df['Result_Check'] = None\n",
    "\n",
    "print(\"Verifying model results and updating 'Result_Check' column.\")\n",
    "df['Result_Check'] = df.apply(verify_model_results, axis=1)\n",
    "\n",
    "# Calculate summary information\n",
    "correct_count = df['Result_Check'].value_counts().get(\"Correct\", 0)\n",
    "wrong_model1_count = df['Result_Check'].str.contains(\"Result_Model1 is wrong\").sum()\n",
    "wrong_model2_count = df['Result_Check'].str.contains(\"Result_Model2 is wrong\").sum()\n",
    "no_check_needed_count = df['Result_Check'].str.contains(\"City not matching\").sum()\n",
    "\n",
    "# Output summary information\n",
    "print(f\"Total rows processed: {len(df)}\")\n",
    "print(f\"Correct matches: {correct_count}\")\n",
    "print(f\"Rows where Result_Model1 is wrong: {wrong_model1_count}\")\n",
    "print(f\"Rows where Result_Model2 is wrong: {wrong_model2_count}\")\n",
    "print(f\"Rows where model comparison was not needed: {no_check_needed_count}\")\n",
    "\n",
    "# Save the modified DataFrame back to Excel\n",
    "print(\"Saving the results to Excel.\")\n",
    "df.to_excel(r\"C:\\Users\\Udhaya\\Desktop\\Udhaya DA Files\\Power BI (Sir File)\\City_Name\\processed_city_name_2.xlsx\", sheet_name=sheet_name, index=False)\n",
    "print(\"Processing completed and file saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf8f38f-7d62-4a5d-aa57-2fec27cfa3ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
